# Store Sales Prediction

**Porblem Statement:** The data scientists at store have collected sales data for 1559 products across 10 stores in different cities. Also, certain attributes of each product and store have been defined. The aim is to build a predictive model and predict the sales of each product at a particular outlet.

Using this model, Store will try to understand the properties of products and outlets which play a key role in increasing sales.

Please note that the data may have missing values as some stores might not report all the data due to technical glitches. Hence, it will be required to treat them accordingly. 

# Goal

Using this model, BigMart will try to understand the properties of products and stores which play a key role in increasing sales.

This project will proceed with the following structure:

1. **Hypothesis Generation** — attempt to better understand the problem by formulating pre-conceived hypothesis and possible factors relating to or affecting the outcome which are the sales

2. **Data Exploration** — exploratory data analysis on categorical and continuous variables and formulating inferences from them

3. **Data Cleaning** — impute missing data and vet for any outliers

4. **Feature Engineering** — one hot encode categorical features into new features with binary values for machine learning algorithm

5. **Model Building** — build predictive machine learning model

## Conclusion

This project showcased a typical (but not a strictly-followed procedure) data analysis workflow. We started off with some **hypotheses generation** to get us thinking about the dataset, its relationships and provided us with potential inferences to explore in subsequent sections. We then moved onto **data exploration** and discovered how the data set needed cleaning and reformatting. After cleaning, we carried out **data cleaning and feature engineering** where we imputed missing values and corrected incorrectly inputted data like the visibility values. Cateogrical features were also one hot encoded into numerical features for prediction. Lastly, we fed our data to several models like Linear Regression, Decision Tree and Random Forest, evaluated their performances and tuned for slightly better results.
